{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Spotify Dataset Sentiment Analysis using Na√Øve Bayes\n",
        "\n",
        "This notebook implements sentiment classification using MultinomialNB with comprehensive text preprocessing techniques.\n",
        "\n",
        "**üöÄ Google Colab Ready** - All dependencies will be installed automatically!\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EhsanulHaqueSiam/spotify-review-sentiment/blob/main/spotify_sentiment_analysis_colab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üîß Setup: Install Dependencies (Colab Only)\n",
        "\n",
        "**Note**: This cell installs required packages. Skip if running locally with existing environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install required packages for Google Colab\n",
        "import sys\n",
        "\n",
        "# Check if running in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üîß Installing packages for Google Colab...\")\n",
        "\n",
        "    # Install packages\n",
        "    !pip install -q kagglehub spacy seaborn\n",
        "\n",
        "    # Download spaCy English model\n",
        "    !python -m spacy download en_core_web_sm\n",
        "\n",
        "    print(\"‚úÖ All packages installed successfully!\")\n",
        "else:\n",
        "    print(\"üìù Running locally - assuming dependencies are already installed\")\n",
        "\n",
        "print(\"üéµ Ready to start sentiment analysis!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaggle_setup"
      },
      "source": [
        "## üîë Kaggle API Setup (Required for Dataset)\n",
        "\n",
        "**For Google Colab users**: Use Colab Secrets (recommended), manual credentials, or upload `kaggle.json` file.\n",
        "## Make Sure you use your credentials from secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaggle_auth"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üîë Setting up Kaggle API for Google Colab...\")\n",
        "\n",
        "    try:\n",
        "        # Option 1: Use Google Colab Secrets (Recommended)\n",
        "        from google.colab import userdata\n",
        "\n",
        "        print(\"üì± Using Google Colab Secrets...\")\n",
        "        print(\"üí° To set up secrets:\")\n",
        "        print(\"   1. Click the üîë key icon in the left sidebar\")\n",
        "        print(\"   2. Add two secrets:\")\n",
        "        print(\"      - Name: KAGGLE_USERNAME, Value: your_kaggle_username\")\n",
        "        print(\"      - Name: KAGGLE_KEY, Value: your_kaggle_api_key\")\n",
        "        print(\"   3. Enable notebook access for both secrets\")\n",
        "\n",
        "        # Get credentials from secrets\n",
        "        kaggle_username = userdata.get('KAGGLE_USERNAME')\n",
        "        kaggle_key = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "        # Set environment variables\n",
        "        os.environ['KAGGLE_USERNAME'] = kaggle_username\n",
        "        os.environ['KAGGLE_KEY'] = kaggle_key\n",
        "\n",
        "        print(\"‚úÖ Kaggle credentials loaded from secrets!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Secrets method failed: {e}\")\n",
        "        print(\"\\nüîß Fallback options:\")\n",
        "\n",
        "        # Option 2: Manual environment variables\n",
        "        print(\"\\nüìù Option A: Set credentials manually\")\n",
        "        print(\"Uncomment and fill in the lines below:\")\n",
        "        print(\"# os.environ['KAGGLE_USERNAME'] = 'your_username'\")\n",
        "        print(\"# os.environ['KAGGLE_KEY'] = 'your_api_key'\")\n",
        "\n",
        "        # Uncomment these lines and add your credentials:\n",
        "        # os.environ['KAGGLE_USERNAME'] = 'your_username'\n",
        "        # os.environ['KAGGLE_KEY'] = 'your_api_key'\n",
        "\n",
        "        # Option 3: Upload kaggle.json file\n",
        "        print(\"\\nüìÅ Option B: Upload kaggle.json file\")\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            print(\"Click to upload your kaggle.json file:\")\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            if 'kaggle.json' in uploaded:\n",
        "                !mkdir -p ~/.kaggle\n",
        "                !cp kaggle.json ~/.kaggle/\n",
        "                !chmod 600 ~/.kaggle/kaggle.json\n",
        "                print(\"‚úÖ Kaggle credentials uploaded successfully!\")\n",
        "            else:\n",
        "                print(\"‚ùå kaggle.json not found in uploaded files\")\n",
        "        except Exception as upload_error:\n",
        "            print(f\"‚ùå File upload failed: {upload_error}\")\n",
        "            print(\"Please use manual credentials setup above.\")\n",
        "\n",
        "else:\n",
        "    print(\"üìù Running locally - using existing Kaggle credentials\")\n",
        "\n",
        "print(\"\\nüí° Get your Kaggle API credentials from: https://www.kaggle.com/settings/account\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task1"
      },
      "source": [
        "## Task 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import basic libraries for data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Basic libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task2"
      },
      "source": [
        "## Task 2: Load and Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_dataset"
      },
      "outputs": [],
      "source": [
        "# Import kagglehub for dataset loading\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download the Spotify dataset from Kaggle\n",
        "print(\"Downloading Spotify dataset from Kaggle...\")\n",
        "try:\n",
        "    # Download the dataset files to local directory\n",
        "    path = kagglehub.dataset_download(\"alexandrakim2201/spotify-dataset\")\n",
        "    print(f\"Dataset downloaded to: {path}\")\n",
        "\n",
        "    # List files in the downloaded directory\n",
        "    files = os.listdir(path)\n",
        "    print(f\"Available files: {files}\")\n",
        "\n",
        "    # Find the CSV file (should be the main dataset)\n",
        "    csv_files = [f for f in files if f.endswith('.csv')]\n",
        "    if csv_files:\n",
        "        csv_file = csv_files[0]  # Take the first CSV file\n",
        "        file_path = os.path.join(path, csv_file)\n",
        "        print(f\"Loading CSV file: {csv_file}\")\n",
        "\n",
        "        # Load the dataset\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(\"Dataset loaded successfully!\")\n",
        "    else:\n",
        "        print(\"No CSV files found in the dataset\")\n",
        "        # Fallback: try to load any file as CSV\n",
        "        if files:\n",
        "            file_path = os.path.join(path, files[0])\n",
        "            df = pd.read_csv(file_path)\n",
        "            print(f\"Loaded {files[0]} as CSV\")\n",
        "        else:\n",
        "            raise FileNotFoundError(\"No files found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading from Kaggle: {e}\")\n",
        "    print(\"Please ensure you have Kaggle API credentials set up.\")\n",
        "\n",
        "    if IN_COLAB:\n",
        "        print(\"\\nüîß For Google Colab:\")\n",
        "        print(\"1. Upload kaggle.json file in the previous cell\")\n",
        "        print(\"2. Or set KAGGLE_USERNAME and KAGGLE_KEY environment variables\")\n",
        "\n",
        "    # Create sample data for demonstration if dataset fails to load\n",
        "    print(\"\\n‚ö†Ô∏è Creating sample data for demonstration...\")\n",
        "    sample_data = {\n",
        "        'Review': [\n",
        "            'Great music service, love the playlists!',\n",
        "            'App crashes frequently, very annoying',\n",
        "            'Amazing sound quality and user interface',\n",
        "            'Too expensive for what it offers',\n",
        "            'Perfect for discovering new music'\n",
        "        ],\n",
        "        'label': ['POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE']\n",
        "    }\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    print(\"Sample dataset created for demonstration purposes\")\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset shape:\", df.shape)\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset description:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task3"
      },
      "source": [
        "## Task 3: Data Preprocessing and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_data"
      },
      "outputs": [],
      "source": [
        "# Import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Explore the target variable (sentiment)\n",
        "# Dataset has 51,473 rows with columns: 'Review' (text) and 'label' (POSITIVE/NEGATIVE)\n",
        "sentiment_column = 'label'  # Sentiment labels: POSITIVE/NEGATIVE\n",
        "text_column = 'Review'  # User review text\n",
        "\n",
        "if sentiment_column in df.columns:\n",
        "    print(\"Sentiment distribution:\")\n",
        "    print(df[sentiment_column].value_counts())\n",
        "\n",
        "    # Visualize sentiment distribution\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    df[sentiment_column].value_counts().plot(kind='bar')\n",
        "    plt.title('Sentiment Distribution')\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Please update the sentiment_column variable with the correct column name\")\n",
        "    print(\"Available columns:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task4"
      },
      "source": [
        "## Task 4: Text Preprocessing - Initialize Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_preprocessing"
      },
      "outputs": [],
      "source": [
        "# Import text preprocessing libraries\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download required NLTK data\n",
        "print(\"üìö Downloading NLTK data...\")\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "print(\"‚úÖ NLTK data downloaded\")\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    print(\"‚úÖ spaCy English model loaded\")\n",
        "except OSError:\n",
        "    print(\"‚ùå spaCy English model not found\")\n",
        "    if IN_COLAB:\n",
        "        print(\"Installing spaCy model...\")\n",
        "        !python -m spacy download en_core_web_sm\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        print(\"‚úÖ spaCy English model installed and loaded\")\n",
        "    else:\n",
        "        print(\"Please install spaCy English model: python -m spacy download en_core_web_sm\")\n",
        "        nlp = None\n",
        "\n",
        "# Initialize tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"üîß Preprocessing tools initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task5"
      },
      "source": [
        "## Task 5: Text Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing_functions"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Basic text cleaning\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to string and lowercase (case folding)\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove user mentions and hashtags\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def tokenize_text(text):\n",
        "    \"\"\"Tokenization\"\"\"\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    \"\"\"Remove stop words\"\"\"\n",
        "    return [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    \"\"\"Stemming\"\"\"\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    \"\"\"Lemmatization\"\"\"\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "def preprocess_text(text, use_stemming=True, use_lemmatization=False):\n",
        "    \"\"\"Complete text preprocessing pipeline\"\"\"\n",
        "    # Clean text\n",
        "    text = clean_text(text)\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = tokenize_text(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = remove_stopwords(tokens)\n",
        "\n",
        "    # Apply stemming or lemmatization\n",
        "    if use_stemming:\n",
        "        tokens = stem_tokens(tokens)\n",
        "    elif use_lemmatization:\n",
        "        tokens = lemmatize_tokens(tokens)\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "print(\"üîß Text preprocessing functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task6"
      },
      "source": [
        "## Task 6: Apply Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apply_preprocessing"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to the text data\n",
        "if text_column in df.columns:\n",
        "    print(\"üîÑ Applying text preprocessing...\")\n",
        "\n",
        "    # Create processed text column\n",
        "    df['processed_text'] = df[text_column].apply(lambda x: preprocess_text(x, use_stemming=True))\n",
        "\n",
        "    # Show examples of original vs processed text\n",
        "    print(\"\\nüìù Example of text preprocessing:\")\n",
        "    for i in range(min(3, len(df))):\n",
        "        print(f\"\\nOriginal: {df[text_column].iloc[i][:100]}...\")\n",
        "        print(f\"Processed: {df['processed_text'].iloc[i][:100]}...\")\n",
        "\n",
        "    # Remove empty processed texts\n",
        "    original_shape = df.shape\n",
        "    df = df[df['processed_text'].str.len() > 0]\n",
        "    print(f\"\\nüìä Dataset shape after preprocessing: {df.shape}\")\n",
        "    if original_shape[0] != df.shape[0]:\n",
        "        print(f\"   Removed {original_shape[0] - df.shape[0]} empty texts\")\n",
        "else:\n",
        "    print(\"‚ùå Please update the text_column variable with the correct column name\")\n",
        "    print(\"Available columns:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task7"
      },
      "source": [
        "## Task 7: Feature Extraction using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfidf_extraction"
      },
      "outputs": [],
      "source": [
        "# Import TF-IDF vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,  # Limit to top 5000 features\n",
        "    min_df=2,          # Ignore terms that appear in less than 2 documents\n",
        "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
        "    ngram_range=(1, 2) # Use unigrams and bigrams\n",
        ")\n",
        "\n",
        "# Fit and transform the processed text\n",
        "if 'processed_text' in df.columns:\n",
        "    print(\"üîÑ Creating TF-IDF features...\")\n",
        "    X_tfidf = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "    print(f\"üìä TF-IDF matrix shape: {X_tfidf.shape}\")\n",
        "    print(f\"üìà Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")\n",
        "\n",
        "    # Show top features\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "    print(f\"\\nüî§ Sample features: {feature_names[:20]}\")\n",
        "    print(\"‚úÖ TF-IDF vectorization completed!\")\n",
        "else:\n",
        "    print(\"‚ùå Processed text not available. Please run the preprocessing step first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task8"
      },
      "source": [
        "## Task 8: Prepare Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_training_data"
      },
      "outputs": [],
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare features and target variables\n",
        "if sentiment_column in df.columns and 'processed_text' in df.columns:\n",
        "    print(\"üîÑ Preparing training and testing data...\")\n",
        "    X = X_tfidf\n",
        "    y = df[sentiment_column]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"üìä Training set shape: {X_train.shape}\")\n",
        "    print(f\"üìä Testing set shape: {X_test.shape}\")\n",
        "    print(f\"\\nüìà Training set sentiment distribution:\")\n",
        "    print(y_train.value_counts())\n",
        "    print(f\"\\nüìà Testing set sentiment distribution:\")\n",
        "    print(y_test.value_counts())\n",
        "    print(\"‚úÖ Data preparation completed!\")\n",
        "else:\n",
        "    print(\"‚ùå Please ensure both sentiment and processed text columns are available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task9"
      },
      "source": [
        "## Task 9: Train MultinomialNB Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_model"
      },
      "outputs": [],
      "source": [
        "# Import MultinomialNB classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Initialize and train MultinomialNB classifier\n",
        "nb_classifier = MultinomialNB(alpha=1.0)  # Laplace smoothing\n",
        "\n",
        "# Train the model\n",
        "print(\"ü§ñ Training MultinomialNB classifier...\")\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Model training completed!\")\n",
        "print(f\"üìä Number of classes: {len(nb_classifier.classes_)}\")\n",
        "print(f\"üè∑Ô∏è Classes: {nb_classifier.classes_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task10"
      },
      "source": [
        "## Task 10: Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "make_predictions"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "print(\"üîÆ Making predictions on test set...\")\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "y_pred_proba = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "print(\"‚úÖ Predictions completed!\")\n",
        "print(f\"\\nüìä Predicted sentiment distribution:\")\n",
        "print(pd.Series(y_pred).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task11"
      },
      "source": [
        "## Task 11: Model Evaluation - Accuracy and Basic Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "basic_metrics"
      },
      "outputs": [],
      "source": [
        "# Import evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate basic evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"üìä === MODEL PERFORMANCE METRICS ===\")\n",
        "print(f\"üéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"üéØ Precision (weighted): {precision:.4f}\")\n",
        "print(f\"üéØ Recall (weighted): {recall:.4f}\")\n",
        "print(f\"üéØ F1-Score (weighted): {f1:.4f}\")\n",
        "\n",
        "# Create a summary dataframe\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'Score': [accuracy, precision, recall, f1]\n",
        "})\n",
        "\n",
        "print(\"\\nüìã Metrics Summary:\")\n",
        "print(metrics_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task12"
      },
      "source": [
        "## Task 12: Detailed Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "classification_report"
      },
      "outputs": [],
      "source": [
        "# Import classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate detailed classification report\n",
        "print(\"üìä === DETAILED CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Convert to dataframe for better visualization\n",
        "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "print(\"\\nüìã Classification Report as DataFrame:\")\n",
        "print(report_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task13"
      },
      "source": [
        "## Task 13: Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "confusion_matrix"
      },
      "outputs": [],
      "source": [
        "# Import confusion matrix and seaborn for visualization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate and visualize confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = nb_classifier.classes_\n",
        "\n",
        "# Create confusion matrix visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print confusion matrix as dataframe\n",
        "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "print(\"üìä Confusion Matrix:\")\n",
        "print(cm_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task14"
      },
      "source": [
        "## Task 14: Feature Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_analysis"
      },
      "outputs": [],
      "source": [
        "# Analyze most important features for each class\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "n_features = 10  # Top 10 features per class\n",
        "\n",
        "print(\"üîç === MOST IMPORTANT FEATURES BY CLASS ===\")\n",
        "for i, class_label in enumerate(nb_classifier.classes_):\n",
        "    # Get feature log probabilities for this class\n",
        "    feature_log_prob = nb_classifier.feature_log_prob_[i]\n",
        "\n",
        "    # Get top features\n",
        "    top_features_idx = np.argsort(feature_log_prob)[-n_features:]\n",
        "    top_features = [(feature_names[idx], feature_log_prob[idx]) for idx in top_features_idx]\n",
        "\n",
        "    print(f\"\\nüè∑Ô∏è Class: {class_label}\")\n",
        "    for feature, prob in reversed(top_features):\n",
        "        print(f\"   {feature}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task15"
      },
      "source": [
        "## Task 15: Model Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "performance_viz"
      },
      "outputs": [],
      "source": [
        "# Create performance visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Metrics bar plot\n",
        "metrics_df.plot(x='Metric', y='Score', kind='bar', ax=axes[0,0], color='skyblue')\n",
        "axes[0,0].set_title('Model Performance Metrics')\n",
        "axes[0,0].set_ylabel('Score')\n",
        "axes[0,0].set_ylim(0, 1)\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "axes[0,0].legend().remove()\n",
        "\n",
        "# 2. Class-wise performance\n",
        "class_metrics = report_df.iloc[:-3, :3]  # Exclude avg rows and support column\n",
        "class_metrics.plot(kind='bar', ax=axes[0,1])\n",
        "axes[0,1].set_title('Class-wise Performance')\n",
        "axes[0,1].set_ylabel('Score')\n",
        "axes[0,1].tick_params(axis='x', rotation=45)\n",
        "axes[0,1].legend(['Precision', 'Recall', 'F1-Score'])\n",
        "\n",
        "# 3. Prediction distribution\n",
        "pred_dist = pd.Series(y_pred).value_counts()\n",
        "pred_dist.plot(kind='pie', ax=axes[1,0], autopct='%1.1f%%')\n",
        "axes[1,0].set_title('Predicted Sentiment Distribution')\n",
        "axes[1,0].set_ylabel('')\n",
        "\n",
        "# 4. True vs Predicted comparison\n",
        "comparison_df = pd.DataFrame({\n",
        "    'True': y_test.value_counts(),\n",
        "    'Predicted': pd.Series(y_pred).value_counts()\n",
        "})\n",
        "comparison_df.plot(kind='bar', ax=axes[1,1])\n",
        "axes[1,1].set_title('True vs Predicted Distribution')\n",
        "axes[1,1].set_ylabel('Count')\n",
        "axes[1,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task16"
      },
      "source": [
        "## Task 16: Sample Predictions Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debug_sparse_matrix"
      },
      "outputs": [],
      "source": [
        "# Debug: Check X_test properties\n",
        "print(f\"üîç X_test type: {type(X_test)}\")\n",
        "print(f\"üîç X_test shape: {X_test.shape}\")\n",
        "print(f\"üîç Number of test samples: {X_test.shape[0]}\")\n",
        "print(f\"üîç Is sparse matrix: {hasattr(X_test, 'toarray')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sample_predictions"
      },
      "outputs": [],
      "source": [
        "# Analyze some sample predictions\n",
        "# Use shape[0] instead of len() for sparse matrix compatibility\n",
        "n_test_samples = X_test.shape[0]\n",
        "sample_size = min(5, n_test_samples)  # Ensure we don't sample more than available\n",
        "sample_indices = np.random.choice(n_test_samples, size=sample_size, replace=False)\n",
        "\n",
        "print(\"üîç === SAMPLE PREDICTIONS ANALYSIS ===\")\n",
        "print(f\"Analyzing {len(sample_indices)} random samples from {n_test_samples} test samples...\")\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    true_label = y_test.iloc[idx]\n",
        "    pred_label = y_pred[idx]\n",
        "    pred_proba = y_pred_proba[idx]\n",
        "\n",
        "    print(f\"\\nüìù Sample {i+1}:\")\n",
        "    print(f\"   True Label: {true_label}\")\n",
        "    print(f\"   Predicted Label: {pred_label}\")\n",
        "    print(f\"   Prediction Confidence: {max(pred_proba):.4f}\")\n",
        "\n",
        "    # Show probabilities for all classes\n",
        "    for j, class_label in enumerate(nb_classifier.classes_):\n",
        "        print(f\"     P({class_label}): {pred_proba[j]:.4f}\")\n",
        "\n",
        "    correct = '‚úÖ' if true_label == pred_label else '‚ùå'\n",
        "    print(f\"   Correct: {correct}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "task17"
      },
      "source": [
        "## Task 17: Model Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_summary"
      },
      "outputs": [],
      "source": [
        "# Final model summary\n",
        "print(\"üéµ === MODEL SUMMARY ===\")\n",
        "print(f\"üìä Dataset: Spotify Sentiment Analysis\")\n",
        "print(f\"ü§ñ Algorithm: Multinomial Na√Øve Bayes\")\n",
        "print(f\"üìà Total samples: {len(df)}\")\n",
        "print(f\"üèãÔ∏è Training samples: {X_train.shape[0]}\")\n",
        "print(f\"üß™ Testing samples: {X_test.shape[0]}\")\n",
        "print(f\"üî§ Number of features: {X_tfidf.shape[1]}\")\n",
        "print(f\"üè∑Ô∏è Number of classes: {len(nb_classifier.classes_)}\")\n",
        "\n",
        "print(\"\\nüîß === PREPROCESSING TECHNIQUES APPLIED ===\")\n",
        "print(\"‚úÖ Tokenization\")\n",
        "print(\"‚úÖ Case folding (lowercase conversion)\")\n",
        "print(\"‚úÖ Punctuation removal\")\n",
        "print(\"‚úÖ Stop words removal\")\n",
        "print(\"‚úÖ Stemming\")\n",
        "print(\"‚úÖ TF-IDF Vectorization\")\n",
        "\n",
        "print(\"\\nüéØ === FINAL PERFORMANCE ===\")\n",
        "print(f\"üéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"üéØ Weighted F1-Score: {f1:.4f}\")\n",
        "print(f\"üéØ Weighted Precision: {precision:.4f}\")\n",
        "print(f\"üéØ Weighted Recall: {recall:.4f}\")\n",
        "\n",
        "print(\"\\nüí° === RECOMMENDATIONS ===\")\n",
        "if accuracy > 0.8:\n",
        "    print(\"‚úÖ Model shows good performance\")\n",
        "elif accuracy > 0.7:\n",
        "    print(\"‚ö†Ô∏è Model shows moderate performance - consider feature engineering\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Model needs improvement - try different preprocessing or algorithms\")\n",
        "\n",
        "print(\"\\nüéâ Analysis completed successfully!\")\n",
        "print(\"\\nüöÄ Great job on completing the Spotify sentiment analysis!\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\\nüíæ Don't forget to save your results!\")\n",
        "    print(\"   File ‚Üí Download ‚Üí Download .ipynb\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
